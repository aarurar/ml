{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1"
      ],
      "metadata": {
        "id": "MPljk5OAXzH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM-X3GTBXuT-"
      },
      "outputs": [],
      "source": [
        "# Ridge regression adds a penalty term to MSE so the over fitting is reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2"
      ],
      "metadata": {
        "id": "OUeqc3GMYFNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Linearity,Independence,No outliers,No overfitting\n",
        "Ridge Regression assumes that the relationship between the dependent and independent variables is linear, but it can handle multicollinearity by adding a penalty term to the cost function.\n",
        "'''"
      ],
      "metadata": {
        "id": "N3We0PmsYG46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3"
      ],
      "metadata": {
        "id": "mJYZaX7TYm5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1)Cross-validation: This method involves dividing the data into k-folds, and then training the Ridge Regression model on k-1 folds and testing on the remaining fold. This process is repeated k times, \n",
        "and the average performance metric (such as mean squared error) is computed for different values of lambda. The value of lambda that gives the best performance metric is chosen as the optimal value.\n",
        "\n",
        "2)Grid search: This method involves defining a range of values for lambda, and then training the Ridge Regression model on each value of lambda. \n",
        "The performance metric is computed for each value of lambda, and the value that gives the best performance metric is chosen as the optimal value.\n",
        "\n",
        "3)Analytical methods: There are analytical methods such as the L-curve method that can be used to determine the optimal value of lambda based on the trade-off between model complexity and goodness of fit.\n",
        "'''"
      ],
      "metadata": {
        "id": "XnddCArXYnzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4"
      ],
      "metadata": {
        "id": "C_B0vVj_ZO5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Yes, Ridge Regression can be used for feature selection. The Ridge Regression model includes a regularization term that penalizes the magnitude of the coefficients of the predictor variables. \n",
        "As lambda increases, the magnitude of the coefficients decreases, and the model becomes more simple. Therefore, we can use Ridge Regression to select the most important features by setting lambda to a value that shrinks some of the coefficients to zero.\n",
        "Features with coefficients that do not shrink to zero are considered important and are selected for the model. This technique is also called L2 regularization or shrinkage.\n",
        "'''"
      ],
      "metadata": {
        "id": "0vTxY5HDZQKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5"
      ],
      "metadata": {
        "id": "22iTsV9ba2Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Ridge Regression is specifically designed to handle multicollinearity in the predictors. When there is multicollinearity in the predictors, \n",
        "the coefficients in ordinary least squares (OLS) regression can become unstable or biased, and the model can have high variance. \n",
        "Ridge Regression addresses this problem by adding a penalty term to the OLS loss function, which shrinks the coefficients towards zero and reduces the variance.\n",
        "\n",
        "In other words, the Ridge Regression model can still perform well in the presence of multicollinearity, as long as the tuning parameter (lambda) is chosen appropriately. \n",
        "The optimal value of lambda depends on the degree of multicollinearity in the predictors. When there is high multicollinearity, a larger value of lambda is needed to increase the amount of shrinkage.\n",
        "'''"
      ],
      "metadata": {
        "id": "w2JbCXBaa3lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "question 6"
      ],
      "metadata": {
        "id": "P_xedeGLbWZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge regression is used commonly for regression purpose. But it can also be used for discrete variable."
      ],
      "metadata": {
        "id": "q24auelEbXmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7"
      ],
      "metadata": {
        "id": "RAR5kpfBbwMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "In Ridge Regression, the coefficients represent the impact of each independent variable on the dependent variable, taking into account the presence of multicollinearity. \n",
        "A positive coefficient indicates a positive association with the dependent variable, while a negative coefficient indicates a negative association.\n",
        "The magnitude of the coefficient indicates the strength of the association. A larger coefficient value means a stronger impact on the dependent variable.\n",
        "'''"
      ],
      "metadata": {
        "id": "dHe2rD9wbxaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8"
      ],
      "metadata": {
        "id": "x8OTXAgGhxez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Ridge Regression can be used for time-series data analysis with some modifications. In time-series data, the observations are not independent of each other and are often autocorrelated.\n",
        "In such cases, we can use an autoregressive model, such as ARIMA (AutoRegressive Integrated Moving Average), to model the time-series data and then apply Ridge Regression to the resulting residuals. \n",
        "This is called ARIMAX-Ridge Regression. \n",
        "'''"
      ],
      "metadata": {
        "id": "VdRD_jPXhyk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}